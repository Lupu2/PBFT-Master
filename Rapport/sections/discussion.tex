\chapter{Discussion}
\label{chapter:Dis}
In this section, we will summarize the benefits and difficulties we encountered when using the tools in our \ac{pbft} implementation. In addition to describing the benefits and disadvantages in regards to our chosen design.

\section{Protocol Abstraction}
%TODO set a better title for this once you realize the word for code accuracy to its protocol description
%First thing you do is give an explanation in regards to protocol abstraction. ONLY IF I KNEW MYSELF AT THIS POINT
%protocol workflow is accurate to the protocol description in regards to step by step
%is workfing for protocol workflow, downside being that it cannot handle messages out of order, as we need to think only on one phase at the time
%really not possible in situation where things can happen in different order aka initalization process, restart process
%workaround being to create seperate code segments with specific protocol steps in mind

Going into this thesis, our goal was to create protocol workflows that were both accurate and faithful to the original protocol description. Our approach to accomplish this was to keep all of the protocol workflows as simplistic by keeping the overall protocol workflow within a single function. The overall workflow should also perform each part of the protocol as synchronous as possible to resemble the protocol description. We refer to these principles as protocol abstraction. For our \ac{pbft} implementation, we only managed to keep all of the protocol-related source code for the normal protocol workflow within a single function. Both the checkpoint and view-change workflow had to be split into several code segments based on the jobs they performed. We would say that we were relatively successful for the normal protocol workflow in terms of simplicity. This is primarily due to the source code performs each protocol phase while still being decently readable. Unfortunately, this came at the cost of not being able to handle pre-prepare protocol messages out of order.

Both the checkpoint and view-change workflows were separated into several code segments primarily due to how both processes could be instantiated in by any of the replicas in the \ac{pbft}, making it severely challenging to keep the workflows orderly and somewhat synchronous. It was generally more natural to segment the checkpoint workflow because it is entirely independent of the normal protocol iterations. This is especially notable for the garbage collection section of the process. Keeping the garbage collection section together with the checkpoint listener would have been relatively messier than having an active checkpoint listener send the result to the server which is responsible for performing the garbage collection process. As for the view-change workflow, it follows a more orderly workflow similar to the normal protocol workflow. However, the view-change workflow required support for restarting processes should the new primary turn out to be faulty. By splitting the operations in the workflow, it would be a lot simpler to provide the timeout functionality needed. Not to mention the view-change functionality itself is quite long, requiring all of the code to be written in a single function would not have simplified the workflow. The workflow would instead be rather messy. In short, we can conclude that there is a somewhat of a fine balance between keeping code orderly and simplistic and providing the functionality we desire. The more complicated the functionality is, the more likely it is that the code also becomes somewhat harder to understand. Therefore, consensus algorithms are very likely to become complicated because the functionality they require is usually quite complex.

\section{Asynchronous workflow}
Asynchronous programming has, in most situations, been beneficial to our \ac{pbft} implementation. Note that when we refer to asynchronous programming in this section, we do include both \code{Task} and \code{CTask} asynchronous operations. Both normal \code{Task} and Cleipnir \code{CTask} operations have practically the same workflow. They both take advantage of the async/await workflow, and they both follow the \code{TAP} abstraction. Because of this, it makes it easy for a developer to create a \code{CTask} workflow if they are familiar with the traditional asynchronous workflow. The \code{await} operator has been valuable for delegating wait points for both the asynchronous workflows and Cleipnir reactive workflow. The use of the \code{await} operator allowed us to create an abstraction for our asynchronous workflow to be read like a synchronous workflow, which greatly helped readability for the workflows. Since the protocol workflows needed to be run together with Cleipnir, we needed to use \code{CTask} asynchronous programming. Except for not being able to use any other traditional asynchronous operations within any of the protocol workflows, there were no other significant disadvantages to running the protocol workflow with Cleipnir asynchronous operations. The \code{CTask} still allowed for the protocol workflow to be run asynchronously, allowing for an easy way to create both several instances of the protocol workflows but also have them run independently. We would argue this is a minor drawback in comparison to support both persistency and the use of Cleipnir's reactive framework for our protocol workflows.
Traditional asynchronous programming has not been helpful for the protocol workflow. On the other hand, traditional asynchronous programming has been a big cornerstone to the application network layer. Meaning traditional asynchronous programming works well with both server handling and with socket programming.  

%downsides
The problems in mixing the two types of asynchronous operations together have already been mentioned numerous times throughout this thesis. As a result, to avoid causing any race conditions or inconsistent states for the application, the application had to be designed to separate the asynchronous operations from each other as much as possible. However, this does create additional limitations for a developer if they were to design a consensus algorithm with the Cleipnir framework. Although asynchronous operations do seem quite handy, it is essential to avoid using them when it is not necessary, or the application could be slowed down as a result. Combine this last issue with combining both \code{CTask} and \code{Task} is rather disastrous. 

\section{Usage of Cleipnir}
In this section, we discuss the benefits provided by the Cleipnir framework. We are primarily focusing on Cleipnir's reactive framework and Cleipnir persistency functionality
\subsection{Reactive Operators}
Cleipnir reactive framework has been beneficial for dealing with operations related to protocol messages. There are three contributions provided to the workflow for using the reactive workflow to handle the protocol messages. The first is that all of the message-related operations, such as validation steps, are performed in sequence, meaning the ordering for the operations is clear and that operators are not called unless the previous operator succeeds. The second reason is that it segments all of the code related to the handling protocol messages away from the overall protocol workflow, making the overall workflow easier to understand. The final reason is that the ideal design of the protocol message handler is an event-based process due to the program not knowing when the protocol message is received, meaning reactive programming is the best approach to use. 
The overall workflow for Cleipnir reactive workflow is simple in design. We require only a single \code{Source} object to be initialized with a specific object type and have this be shared between two parts of the system. The first part of the system emits the item, while the other part listens to the stream for any incoming items and performs the desired reactive operators on the received item. The usage of reactive stream operators is generally straightforward but may be difficult for developers unfamiliar with query languaging. The Cleipnir reactive framework has, for the majority of the time, had the reactive operators we needed, despite having a low amount of reactive operators compared to other reactive \ac{api}. Regardless, Stidsborg has demonstrated that the process of adding other reactive operators from the Reactive X library is not challenging. The \code{Merge} operator was added to Cleipnir reactive framework during this project due to our need to stop the normal protocol workflow, which took less than a day. The source code for the reactive workflow has also shown to be quite reusable, considering we have used relatively the same workflow for all of our protocol workflows. From our usage of the Cleipnir reactive framework for our implementation of the \ac{pbft} workflows, we would argue that it is well suited for event-driven programming. 

A major drawback we have encountered with the Cleipnir reactive framework is that the Cleipnir execution engine is almost always is required to be used when performing an emit to the protocol workflow. This particular issue may only be relevant for our design. Still, it is pretty clear that if any object is to be transformed by the reactive stream, the Cleipnir execution engine is needed to schedule the emit of the protocol message. Otherwise, the reactive stream attempts to handle multiple protocol messages concurrently, which causes the object to become inconsistent. With the help of the Cleipnir execution engine, we can enforce a \ac{fcfs} ordering on the protocol messages, avoiding this issue entirely, but that in itself may not always be beneficial. The most notable issue is when an emit takes place within a \code{CTask} asynchronous operation. Scheduling operations and performing the desired operations using the Cleipnir execution is treated as a traditional asynchronous operation. Therefore the workflow within the \code{CTask} cannot wait for the scheduled operation to finish as it is performed on another thread, which can cause problems if the scheduled operations are vital for the rest of the workflow. 

We can also document that stopping an active workflow that is waiting for the result of a reactive stream is not very simple. We discussed in the \autoref{sec:startview} how we made a workaround for this issue, but it is quite the situational solution. From our experience, it is more beneficial to design any workflows with more restrictive \code{Source} operators early, to keep the workflow active but essentially filter out any of the future protocol messages as soon as possible. It does waste resources, but the overall design of workflow will be a lot more desirable. 

The most detrimental disadvantage we encountered regarding the Cleipnir reactive workflow lies in trouble dealing with protocol message messages being received out of order. We already discussed how our current \ac{pbft} implementation struggles in certain parts of the program to handle protocol messages being received out of order. This issue does have two known workarounds, although both do limit the design of the workflow. The first workaround is to initialize and have each \code{Source} object start listening on the reactive streams as early as possible in the workflow. Otherwise, any protocol messages received out of order or received too early are lost. This is the workflow we primarily used in our workflows, unfortunately not always possible to use this workaround, as shown in our pre-prepare phase implementation. The other known workaround would be to use unique \code{Source} objects for each and every protocol message type to avoid any of the other \code{Source} object filtering out any messages received for that protocol type. However, this workaround needs a lot of extra \code{Source} objects to be initialized and individual object types for every type for every protocol message, which can become quite extensive.

To summarize, Cleipnir’s reactive framework is well suited for segmenting operations in a consensus algorithm that is reliant on event-based programming. In addition, it is relatively easy for developers to use once the basics have been learned. It also helps make the general workflow more compact and readable thanks to its ability to use chain operators on the reactive stream. However, the reactive framework can struggle with handling several events types when they are all listening on the same \code{Source} object when the ordering of the events matters. The reactive framework is also tricky to use on a workflow that requires handling forms of exceptions to normal workflow. Since consensus algorithms must be able to handle situations where parties in the network stop responding, this can become a frequent issue. However, there do exist workarounds for handling some of the issues discussed.  We believe that better workarounds are also bound to be discovered in the future. 

\subsection{Persistency}
Persistency has not been the primary focus for our \ac{pbft} implementation. We have, however, been attempting to take advantage of the Cleipnir persistency functionality to persist relevant data for our implementation. Our main contributions here lie in making sure all the protocol workflows are run within \code{CTask} asynchronous operations. In addition, we used Cleipnir hybrid persistency functionality to create appropriate serializer and deserializer for our protocol objects.
Unfortunately, the current \ac{pbft} implementation does not support functional persistency. The reason why the persistency does not work properly is uncertain. We have discovered at least two issues. The first issue is that the protocol logger, for some reason, does not persist all the entries in the logger. As of now, no distinguishable pattern has been found with the data that gets lost. Either way, losing certificates in the logger does create big problems for our restarted application. The other problem is that some of the \code{Source} objects which are linked to the server gets duplicated when the system is rebooted. This means that in the persisted system, there suddenly exist two \code{Source} objects with the exact same reference. This is a big problem because each time the server emits a message to the duplicated \code{Source} object, it emits the message to both the original and duplicate \code{Source} objects. This, in turn, can cause two identical iterations of the protocol workflow to occur, meaning they work on the same sequence number. In the worst-case scenario, both protocol iterations store the resulting protocol certificates on the same sequence number, leading to scenarios where the logger suddenly has four certificates recorded for a single sequence number. The logger is only meant to store a maximum of two protocol certificates for a protocol iteration, so this is quite the issue for future protocol states.

However, we have tested the persistency functionality for our implementation by using smaller practical examples and unit tests. We can verify that the persistency works well for smaller segments of our application, such as testing the persistency for most of our protocol objects.
We can at least certify that the hybrid persistency functionality works quite well for Cleipnir. It is both convenient and straightforward to choose segments of an object to persist using the object-oriented design to the serializer and deserializer. Although, a developer can potentially make mistakes if they unaware of the limitations to Cleipnir ability to persist certain data types.


\iffalse
Going into this thesis our goal was to create protocol workflows that were both accurate and faithful to the original protocol description. Our approach to accomplish this was to keep all of the protocol workflows as simplistic by keeping the overall protocol workflow within a single function. The overall workflow should also perform each part of the protocol as synchronous as possible to resemble the protocol description. We refer to these principles as protocol abstraction. For our \ac{pbft} implementation, we only managed to keep all of the protocol-related source code for the normal protocol workflow within a single function. Both the checkpoint and view-change workflow had to be split into several code segments based on the jobs they performed. We would say that we were relatively successful for the normal protocol workflow in terms of simplicity. This is primarily due to the source code performs each protocol phase while still being decently readable. Unfortunately, this came at the cost of not being able to handle pre-prepare protocol messages out of order.

Both the checkpoint and view-change workflows were separated into several code segments primarily due to how both processes could be instantiated in by any of the replicas in the \ac{pbft}, making it severely challenging to keep the workflows orderly and somewhat synchronous. It was generally more natural to segment the checkpoint workflow due to how the process is completely independent of the normal protocol iterations. This is especially notable for the garbage collection section of the process. Keeping the garbage collection section together with the checkpoint listener would have been relatively messier than having an active checkpoint listener send the result to the server which is responsible for performing the garbage collection process. As for the view-change workflow, it has a follows a more orderly workflow similar to the normal protocol workflow. However, the view-change workflow required support for restarting processes should the new primary turn out to be faulty. By splitting the operations in the workflow it would be a lot simpler to provde timeout functionality needed. Not to mention the view-change functionality itself is quite long, requiring all of the code to written in a single function would have not simplified the workflow, it would instead made the workflow rather messy. In short we can conclude that there is a somewhat of a fine balance between keeping code orderly and simplistic and provided the functionality we desire. The more complicated the functionality is, the more likely it is that the code also becomes rather hard to understand. Therefore, consensus algorithms are very likely to become complicated because the functionality they require is usually rather complex.
\section{Asynchronous workflow}
\iffalse
%Benefits
-await operator reactive programming framework Cleipnir provided
-beneficial for our server implementation
-allowed us to easily create task that ran seperate from the main protocol workflow
-Easy to create and handle multiple instances of our protocol implementation, remember to not alter the state inside the function!
-not to difficult to use in combination with traditional synchronous design, due to async await design
%disadvantages
-issues in regards to using traditional async with Cleipnir, caused race conditions
-Overusage can slow down the system unnecessarily
\fi
%benefits
Asynchronous programming has in most situations, been beneficial to our \ac{pbft} implementation. Keep in mind that when we refer to asynchronous programming in this section, we do include both \code{Task} and \code{CTask} asynchronous operations. Both normal \code{Task} and Cleipnir \code{CTask} operations have practically the same workflow. They both take advantage of the async/await workflow, and they both follow the \code{TAP} abstraction. Because of this, it makes it easy for a developer to create a \code{CTask} workflow if they are familiar with the traditional asynchronous workflow. The \code{await} operator has been valuable for delegating wait points for both the asynchronous workflows and Cleipnir reactive workflow. The use of the \code{await} operator allowed us to create an abstraction for our asynchronous workflow to be read like a synchronous workflow, which greatly helped readability for the workflows. 
Since the protocol workflows needed to be run together with Cleipnir, we needed to use \code{CTask} asynchronous programming. Except for not being able to use any other traditional asynchronous operations within any of the protocol workflow, there were no other major disadvantages to running the protocol workflow with Cleipnir asynchronous operations. The \code{CTask} still allowed for the protocol workflow to be run asynchronously, allowing for an easy way to create both several instances of the protocol workflows but also have them run independently. Which we would argue is a small price in order to support both persistency and the use of Cleipnir reactive framework for our protocol workflows.
Traditional asynchronous programming has not been helpful for the protocol workflow. On the other hand, traditional asynchronous programming has been a big cornerstone to the application network layer. Meaning traditional asynchronous programming works well with both server handling and with socket programming.  

%downsides
 It has already been mentioned numerous times in this thesis in regards to the problems of mixing the two types of asynchronous operations. As a result, to avoid causing any race conditions or inconsistent states for the application, the application had to be designed to separate the asynchronous operations from each other as much as possible. However, this does create additional limitations for a developer if they were to design a consensus algorithm with the Cleipnir framework. Although asynchronous operations do seem quite handy, it is essential to avoid using them when it is not necessary, or the application could be slowed down as a result. Combine this last issue with combining both \code{CTask} and \code{Task} is rather disastrous. 
\section{Usage of Cleipnir}
\iffalse
%reactive
%benefits
-Really simple to use once gotten the used to it
-Cleipnir does provide as promised most of the necessary reactive operators that you would need. Thomas created the ones missing, meaning adding new ones should not be that big of an issue
-Extremely useful for handling the protocol messages in a step by step manner 
-Code is very reusable :)
-Very useful in general for handling event-driven programming
%downsides
-Practically have to use the Cleipnir execution engine if you want to be absolutely certain the messages arrive in fcfs fashion(from our experience)
-Really not easy to stop an active stream, current workaround was limiting to say the least
-Forces programmer to either make a lot of additional \code{Source} objects or initialize the reactive streams as early as possible otherwise you most likely will lose messages/get stuck due to filtering out to many phase messages.

%persistent
-unable to get the persistency to work for my implementaiton, unsure as to why...explain main problems
-General the way to assign Cleipnir properties to an object is intiuative and easy to use, kinda also needed if Cleipnir is to be used correctly
-Written enough test/tried practical examples to know that on a small basis the persistency works well enough
\fi
In this section we will discuss the benefits provided by the Cleipnir framework with focus primarily on the reactive framework and Cleipnir persistency functionality
\subsection{Reactive Operators}
\iffalse
(This section is about: discussing the fact that there exist two implementations for view-change and checkpoint, and their differences. perhaps better for evaluation?)
(Action: move this to discussion/imp discussion, benefits of using reactive operations vs object directly.)
Probably be moved again as this is not a summary!
There currently exist two different implementations for checkpointing and view-changes. Both versions are still documented in the source code, where the second implementations and preferred implementations have the letter 2 at the end of its name. The workflow for both of them remains practically the same. The main difference between the two lies in how the implementations handle  the creation of certificates. A certificate is not deemed valid until it has received $2f+1$ unique and valid message for the corresponding message type. The second implementation performs the message validation, adding a message to proof list and proof list validation over a \code{Source} object using reactive operators. Meanwhile the first implementation performs these same operations for certificates inside the checkpoint certificate itself inside. The processes are performed sequentially once the append function is called with a message. Regardless of which implementation is used, once the certificates are deemed valid, another emit has to be called for another \code{Source} object to allow the view-change and checkpoint operations to continue with their next operations. Essentially this \code{Source} acts as a signal to tell the workflow to continue with the next operations. The first implementation is required to add a callback function to the certificate object in order to call the server to emit the signal. The second implementation is initialized with the callback function reference, allowing it to easily make a call once all the reactive operators are completed. The second implementation was made in order to accommodate the need for more reactive operations in our application. From our experience the second implementation generally performed better than the first implementation and was also for the most part more consistent, and easier to code. The first implementation sometimes encountered issues with the callback function, especially the view-change implementation. 
\fi
%reactive
%benefits
Cleipnir reactive framework has been beneficial for dealing with operations related to protocol messages. There are three contributions provided to the workflow for using the reactive workflow to handle the protocol messages. The first is that all of the message-related operations such as validation steps are performed in sequence, meaning the ordering for the operations is clear and that operators are not called unless the previous operator succeeds. The second reason is that it segments all of the code related to the handling protocol messages away from the overall protocol workflow, making the overall workflow easier to understand.  The final reason is that the ideal design of the protocol message handler is an event-based process due to the program not knowing when the protocol message is received, meaning reactive programming is the best approach to use. 
The overall workflow of Cleipnir reactive workflow is simple in design. We require only a single \code{Source} object to be initialized with a specific object type and have this be shared between two parts of the system. The first part of the system emits the item, while the other part listens to the stream for any incoming items and performs the desired reactive operators on the received item. The usage of reactive stream operators is generally straightforward but may be difficult for developers unfamiliar with query languaging. The Cleipnir reactive framework has, for the majority of the time, had the reactive operators we needed, despite having a low amount of reactive operators compared to other reactive \ac{api}. Regardless, Stidsborg has demonstrated that the process of adding other reactive operators from the Reactive X library is not challenging. The \code{Merge} operator was added to Cleipnir reactive framework during this project due to our need to stop the normal protocol workflow, which took less than a day. The source code for the reactive workflow has also shown to be quite reusable, considering we have used relatively the same workflow for all of our protocol workflows. From our usage of the Cleipnir reactive framework for our implementation of the \ac{pbft} workflows, we would argue that it has been helpful in dealing with event-driven programming. 

A major drawback we have encountered with the Cleipnir reactive framework is that the Cleipnir execution engine is almost always is required to be used when performing an emit to the protocol workflow. This particular issue may only be relevant for our design. Still, it is quite clear that if any object is to be transformed by the reactive stream, the Cleipnir execution engine is needed to schedule the emit of the protocol message. Otherwise, the reactive stream attempts to handle multiple protocol messages concurrently, which causes the object to become inconsistent. With the help of the Cleipnir execution engine, we can enforce a \ac{fcfs} ordering on the protocol messages, avoiding this issue entirely, but that in itself may not always be beneficial. The most notable issue is when an emit takes place within a \code{CTask} asynchronous operation. Scheduling operations and performing the desired operations using the Cleipnir execution is treated as a traditional asynchronous operation. Therefore the workflow within the \code{CTask} cannot wait for the scheduled operation to finish as it is performed on another thread, which can cause problems if the scheduled operations are vital for the rest of the workflow. 

We can also document that stopping an active workflow that is waiting for the result of a reactive stream is not very simple. We discussed in the \autoref{sec:startview} how we made a workaround for this issue, but it is quite the situational solution. From our experience, it is more beneficial to design any workflows with more restrictive \code{Source} operators early, to keep the workflow active but essentially filter out any of the future protocol messages as soon as possible. It does waste resources, but the overall design of workflow will be a lot more desirable. 

The most detrimental disadvantage we encountered regarding the Cleipnir reactive workflow lies in trouble dealing with protocol message messages being received. We already discussed how our current \ac{pbft} implementation struggles in certain parts of the program to handle protocol messages being received out of order. This issue does have two known workarounds, allthough both do limit the design of the workflow. The first workaround is to initialize and have each \code{Source} object start listening on the reactive streams as early as possible in the workflow. Otherwise, any protocol messages received out of order or received too early are lost. This is the workflow we primarily used in our workflows, unfortunately not always possible to use this workaround, as shown in our pre-prepare phase implementation. The other known workaround would be to use unique \code{Source} objects for each and every protocol message type to avoid any of the other \code{Source} object filtering out any messages received for that protocol type. However, this workaround does require a lot of extra \code{Source} objects to be initialized and individual object types for every type for every protocol message, which can become quite extensive.

\subsection{Persistency}
%reformat to be less informative and more a summary, may want to have this as a seperate section in the implementation
\iffalse
Currently the \ac{pbft} implementation does not support functional persistency. The reason why the persistency  does not work properly is uncertain. There are two main issues as of now. The first issue is that the protocol logger for some reason does not persist all the entries in the logger. As of now, no distinguishable pattern has been found with the data which is lost. Either way, losing certificates in the logger does create big problems. The other problem is that some of the \code{Source} objects that are linked to the server get duplicated when persisted. This means that in the persisted system there suddenly exist two \code{Source} objects with the exact same reference. This becomes a problem, because each time the server emits a message to the duplicated \code{Source} object, it emits the message to both the original and duplicate \code{Source}. This in turn can cause two identical iterations of the protocol workflow to occur. This even includes storing the resulting protocol certificates to the logger with the same sequence number, leading to scenarios where the logger suddenly has four certificates recorded for a single sequence number. The logger is only meant to store a maximum of two protocol certificates for a protocol iteration, so this is quite the issue for future protocol states.
\fi
Persistency has not been the primary focus for our \ac{pbft} implementation. We have, however, been attempting to take advantage of the Cleipnir persistency functionality to persist relevant data for our implementation. Our main contributions here lies in making sure all the protocol workflows are run within \code{CTask} asynchronous operations. In addition, we used Cleipnir hybrid persistency functionality to create appropriate serializer and deserializer for our protocol objects.
Unfortunately, the current \ac{pbft} implementation does not support functional persistency. The reason why the persistency does not work properly is uncertain. We have discovered at least two issues. The first issue is that the protocol logger, for some reason, does not persist all the entries in the logger. As of now, no distinguishable pattern has been found with the data that gets lost. Either way, losing certificates in the logger does create big problems for our restarted application. The other problem is that some of the \code{Source} objects which are linked to the server gets duplicated when the system is rebooted. This means that in the persisted system, there suddenly exist two \code{Source} objects with the exact same reference. This is a big problem because each time the server emits a message to the duplicated \code{Source} object, it emits the message to both the original and duplicate \code{Source} objects. This in turn can cause two identical iterations of the protocol workflow to occur, meaning they work on the same sequence number. In the worst-case scenario, both protocol iterations store the resulting protocol certificates on the same sequence number, leading to scenarios where the logger suddenly has four certificates recorded for a single sequence number. The logger is only meant to store a maximum of two protocol certificates for a protocol iteration, so this is quite the issue for future protocol states.

However, we have tested the persistency functionality for our implementation by using smaller practical examples and unit tests. We can verify that the persistency works well for smaller segments of our application, such as testing the persistency for most of our protocol objects.
At the very least, we can confirm that the hybrid persistency functionality works quite well for Cleipnir. It is both convenient and straightforward to choose segments of an object to persist using the object-oriented design to the serializer and deserializer. Although, a developer can potentially make mistakes if they unaware of the limitations to Cleipnir ability to persist certain data types.
\fi