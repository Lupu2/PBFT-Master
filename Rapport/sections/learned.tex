\section{Lessons Learned}
\iffalse
-PBFT
-Asynchronous programming with C#, Task architecture
-Reactive Programming basics
-Overall knowledge for Cleipnir
-Issues and advantages in regards to the topics listed over. For instance a lot of time was wasted due to not fully grasping how Cleipnir work internally when performing the reactive part and the CAwaitable emission --> resulting a month of frustration trying to figure out why collision errors occur.
-Lack of documentation can be quite fatal for continued support.
-The multitude of potential issues that could occur that aren't necessary dealt with in the theoretical consensus algorithm or pseudo code.
-Cleipnir and how it interacts with the other programming paradigms. Eks: A clear distinction has to made in regards to what code is run inside Cleipnir(the persistent part) and what is not called in Cleipnir (orthogonal part), mixing these will cause disastrous results, which we infact encountered several times during implementation.
%-Unit testing, simplicity of C# unit testing, issues in regards to unit testing networking as running tests in parallel causes inconsistent results and at worst case inf-loops(don't think this is really all that useful)
\fi
%first draft, probably be heavly changed after writing the other parts of the thesis

\subsection{Consensus algorithm}
At the start of this thesis our knowledge in regards to consensus algorithms were limited to practical analysis of the Paxos algorithm. We had never encountered any information in regards to the PBFT consensus algorithm, therefore some time needed to be spent on learning the inner workings of the PBFT algorithm. In addition, Cleipnir had already been used to implement the Paxos and Raft consensus algorithms, therefore some time was also spent on understanding the basics of the Raft consensus algorithm. The transition from one consensus algorithm when looking solely on the protocol descriptions is not all that complicated. This is mostly due to similarities found in their functionality. Components used to implement a functional consensus algorithm are usually shared by many consensus algorithms. This in turn makes it easier for someone familiar with one algorithm to understand another. An example of this being that all three previous mentioned algorithms uses an election model in order to make a decision over the network. Furthermore one party in the election is given the leader role and is therefore responsible for governing the election process. Hence understanding the basic principles behind the PBFT algorithm through the project description was not challenging. 

However, consensus algorithms are notoriously difficult to implement. This is because the protocol description are by design written to as simple as possible, otherwise developers would have issues fully understand the basics on how they operate. This can unfortunately lead to some information being omitted, which can cause issues when designing an implementation for the algorithm. This was especially apparent for our implementation, since the goal our goal was to make the protocol workflow as simplistic as possible. Several times during development new issues became apparent in regards specific scenarios or circumstances occurring during the protocol workflow. This was especially relevant when thinking of all the different issues that could potentially occur when a restarted replica with out of date persisted state attempted to collaborate with the other updated replicas. 

In most of these cases we had to decide whether or not it be worth to introduce additional complexity to the implementations in order to handle these issues, or to simply try to avoid them. In most realistic scenarios the obvious choice would be to fix the issue, even if it adds more complexity to your system. Unfortunately, since our goal was to attempt to implement a very simple implementation, in addition to upholding a time constraint, we had to prioritize differently. Which in turn made our implementation less desirable compare to other more complex implementations. In short our experience working on implementing the PBFT algorithm led us to believe that the largest difficulty in regards to the implementation of consensus algorithms does not necessarily lie lack of understanding the technicalities within the consensus algorithm, but rather in how to implement the protocol so that it can handle every possible errornous situation that may occur.

\subsection{Asynchronous programming}
Going into this thesis our experience using asynchronous programming were limited and were solely based on a few previous projects. In addition the asynchronous programming used in these previous projects were using the JavaScript asynchronous framework. Although the language barrier between the asynchronous tools were minimal, there were a few subtle differences. The naming conventions being different for similar operations were especially annoying. An example of this being how C\# \code{Task} not being far from JavaScript \code{Promise}. Overall since both the asynchronous frameworks supports the use of the async/await operators, programming asynchronous workflow were relatively similar. 

On the other hand there were issues encountered in our application due to lack of understanding behind the details for the async and await operators early in development. Originally our application used asynchronous programming for a lot tasks related to both networking and protocol handling which caused a lot of internal nested state machines being created. Not only was it a pain to attempt to debug issues regarding nested state machines, but it further escalated when nested async/await operators were used inside \code{CTask}'s for normal \code{Task}, which created additional threads. The result being a lot of race conditions, inconsistent states and generally a nightmare to debug. The simple solution was to make any unnecessary asynchronous task become synchronously operations, which in turn removed a lot of the nested state machines as well as removing the \code{CTask} threading issue.

In short, due to our over usage of async/await workflow for tasks that didn't necessarily needed to be asynchronous lead to issues for our application. Therefore, it is important when designing an asynchronous application to have a clear view over which computing tasks requires asynchronous workflow and which can be satisfied by synchronous workflow. Using asynchronous programming for tasks were it is not needed only causes extra complexity to the code and as a result is harder to debug and also unnecessarily slows down the system.

\subsection{Reactive programming}
At the beginning of this project, we had very little to no previous experience in regards to reactive programming. Therefore it became quite the challenge learning the basics for reactive programming. Specifically the main challenge became using the basics for reactive programming in order to understand Cleipnir's reactive functionality. Majority of the documentation and tutorials around the web in regards to reactive programming focused mostly on the basics and the corner stone used for implementing their own reactive operators. This did not quite translate well for our project as all of the reactive layer as already implemented in Cleipnir. Cleipnir reactive functionality in itself is very easy to use and is not all that hard to learn. However, making a direct comparison to the official reactive documentation~\cite{WEB:ReactiveXMainPage} and Cleipnir.Rx was not so simple. This mostly due to the cornerstones having different name schemes between the two. (add more stuff here later)

In terms of our experience using the Cleipnir reactive layer it exceptionally easy to use once you learned the basics. Although Cleipnir currently lacks support for the majority of the reactive operators listed in the documentation, the current support still has the majority of the most used reactive operators. During development only a single time did we encounter an issue in which we needed a reactive operator that was currently not supported. Thankfully Thomas added that missing reactive operator within a single day, essentially proving that Cleipnir's current design allows for developers to easily add missing reactive operators should the need ever arise. As for the usage of the reactive paradigm in the protocol workflow. The code operations performed over the reactive streams works well and easy to keep track of due to how simple it is to chain reactive operators. Not to mention quite easy to read. On the other hand, chaining reactive operations can be somewhat restricting in some circumstances. The most troublesome issue encountered in regards to working with reactive operators was to handle exceptions to the protocol workflow. In our case it was stopping the reactive operators in the case where a view-change occurred. When the program is required to wait for a reactive operator to finish it is required to wait until all of the reactive operators have finished in the stream, making it very easy to get stuck when the source doesn't get the desired items to the stream. There are two notable workarounds to this problem. The first is to simply ignore the problem since it source objects should only be listened to in \code{CTask} asynchronous functions, therefore it won't block the main execution thread even if it never finishes all of the reactive operators. If the reactive operators has strict \code{Where} clauses the old listeners won't be effected by new items, since the items are filtered out long before it can effect the program in any way. This means the workaround is essentially just letting the listener run stuck until it is eventually garbage collected while instead move on by creating new \code{CTask} instead. The second workaround uses the \code{Merge} operator to have the listener listen to changes on two different streams. By this method it is possible to effectively terminate the listener if it receives an item from the second source, as this is counted as irregular activity. This is the method used in our PBFT implementation to handle exiting existing instances of the PBFT workflow in order to change view for the system. This workaround also has its fair share of issues. In order to use the \code{Merge} operator it would require both the source objects to listen for the same type of object. This is not always easy to coordinate, especially when the other operators for the listener transforms the stream to work on another object type. In addition, the \code{Merge} operator also works like any other operator. If the \code{Merge} is triggered by the other source object and the operator is called early in the stream, than the item received is still required to pass the other operators in order to terminate the listener. Which puts it back to the state of the original problem. The item received by the other source must also be unique so that the rest of the workflow can terminate the process when it receives item from that other \code{Source} object. 

To summarize, the use of reactive handlers works well for segmenting operations to perform for the consensus algorithm when a new event is received in the network layer. In addition it is relatively easy for developers to use and is a lot easier to read the workflow in comparison to traditional programming. However, reactive handlers can be tricky to deal with when used in protocol workflow's that needs to handle execptions to the normal workflow. As consensus algorithms must handle situations where parties on the network stops responding, this can become a rather frequent issue. It therefore would be most beneficial if additional workarounds where discovered for handling this issue.  

\subsection{Cleipnir}
