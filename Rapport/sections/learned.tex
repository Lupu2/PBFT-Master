\section{Lessons Learned}
\iffalse
-PBFT
-Asynchronous programming with C#, Task architecture
-Reactive Programming basics
-Overall knowledge for Cleipnir
-Issues and advantages in regards to the topics listed over. For instance a lot of time was wasted due to not fully grasping how Cleipnir work internally when performing the reactive part and the CAwaitable emission --> resulting a month of frustration trying to figure out why collision errors occur.
-Lack of documentation can be quite fatal for continued support.
-The multitude of potential issues that could occur that aren't necessary dealt with in the theoretical consensus algorithm or pseudo code.
-Cleipnir and how it interacts with the other programming paradigms. Eks: A clear distinction has to made in regards to what code is run inside Cleipnir(the persistent part) and what is not called in Cleipnir (orthogonal part), mixing these will cause disastrous results, which we infact encountered several times during implementation.
%-Unit testing, simplicity of C# unit testing, issues in regards to unit testing networking as running tests in parallel causes inconsistent results and at worst case inf-loops(don't think this is really all that useful)
\fi
%first draft, probably be heavly changed after writing the other parts of the thesis
REWRITE THIS SECTION!!!! MINDRE historie lesing, bryr oss ikke om det du har gjort noe særlig med mindre det er godt. Hvis du har noe viktig/revosulerende så beskriv det, men ellers ikke nødvendig.
\subsection{Consensus algorithm}
At the start of this thesis our knowledge in regards to consensus algorithms were limited to having previously implemented the Paxos algorithm using Golang language~\cite{WEB:golangmainpage}. We had never encountered any information in regards to the \ac{pbft} consensus algorithm, therefore some time needed to be spent on learning the inner workings of the \ac{pbft} algorithm. In addition, Cleipnir had already been used to implement the Paxos and Raft consensus algorithms. Therefore some time was also spent on understanding the basics of the Raft consensus algorithm to fully understand the source code used for the Raft implementation. The transition from one consensus algorithm when looking solely on the protocol descriptions is not all that complicated. This is mostly due to similarities found in their functionality. Components used to implement a functional consensus algorithm are shared by many consensus algorithms. This in turn makes it easier for someone familiar with one algorithm to understand another. An example of this being that all three previously mentioned algorithms use an election model in order to make a decision over the network. Furthermore one party in the election is given the leader role and is therefore responsible for governing the election process. Hence understanding the basic principles behind the \ac{pbft} algorithm through the project description was not challenging.

However, consensus algorithms are notoriously difficult to implement. This is because the protocol descriptions are by design written to be as simple as possible, otherwise developers would have issues fully understanding the basics on how they operate. This can unfortunately lead to some information being omitted, which can cause issues when designing an implementation for the algorithm. This was especially apparent for our implementation, since our goal was to make the protocol workflow as simplistic as possible using the tools at hand. Several times during development new issues became apparent in our design when certain scenarios or circumstances occurred during the protocol workflow. This was especially noticeable when thinking of all the different issues that could potentially occur when a restarted replica with an out of date persisted state attempted to collaborate with the other replicas.

In most of these cases we had to decide whether or not it was worth it to introduce additional complexity to the implementations in order to handle these issues, or to simply try to avoid them altogether. In most realistic scenarios the obvious choice would be to fix the issue, even if it adds more complexity to your system. Unfortunately, since our goal was to attempt to implement a very simple implementation, in addition to upholding a time constraint, we had to prioritize differently. Which in turn made our implementation less desirable compared to other more complex implementations. In short, our experience working on implementing the \ac{pbft} algorithm led us to believe that the largest difficulty in regards to the implementation of a consensus algorithm does not necessarily lie in lack of understanding the technicalities within the consensus algorithm. Instead we believe it lies in having to make an implementation that follows the simple protocol description, while still needing to make sure that the state of the system is not affected by any potential issue that can occur in any of the units in the systems. 

\subsection{Asynchronous programming}
Going into this thesis our experience using asynchronous programming were limited and were solely based on a few previous code projects. In addition the asynchronous programming used in these projects used the JavaScript asynchronous framework. Although the language barrier between the asynchronous tools were minimal, there were a few subtle differences. An example of this being how C\# \code{Task} objects function very similarly to \code{Promise} in JavaScript. Overall since both the asynchronous frameworks support the use of the async/await operators, programming asynchronous workflows were relatively similar.

On the other hand there were issues encountered in our application due to lack of understanding behind the details for the async and await operators early in development. Originally our application used asynchronous programming for a lot of tasks related to both networking and protocol handling which caused a lot of internal nested state machines to be created due to using async/await inside other async/await operators. Not only was it a pain to attempt to debug issues regarding nested state machines, but it further escalated when nested async/await operators were used inside \code{CTask}'s for normal \code{Task} functions, which created additional threads to appear as well. The result being a lot of race conditions, inconsistent states and just generally a nightmare to debug. The simple solution was to make any unnecessary asynchronous task become synchronous operations, which in turn removed a lot of the nested state machines. The second change being to separate \code{Task} functions and \code{CTask} functions as much as possible, which further helped since it removed the race conditions.

In short, due to our over usage of async/await workflow for tasks that didn't necessarily need to be asynchronous lead to a lot of issues for our application. Therefore, it is important when designing an asynchronous application to have a clear view over which computing tasks require asynchronous workflow and which can be satisfied by synchronous workflow. Using asynchronous programming for tasks where it is not needed only causes extra complexity to the code and as a result is not only harder to debug but also unnecessarily slows down the system.

\subsection{Reactive programming}
At the beginning of this project, we had very little to no previous experience in regards to reactive programming. Therefore it became quite the challenge learning the basics for reactive programming. Specifically the main challenge became using the basics for reactive programming in order to understand Cleipnir's reactive functionality. Majority of the documentation and tutorials around the web in regards to reactive programming focused mostly on the basics and the cornerstones used for implementing their own reactive operators. This did not quite translate well for our project as all of the reactive layers were already implemented in Cleipnir. Cleipnir reactive functionality in itself is very easy to use and is not all that hard to learn. However, making a direct comparison to the official reactive documentation~\cite{WEB:ReactiveXMainPage} and Cleipnir.Rx was not so simple. This mostly due to the cornerstones having different name schemes between the two.  (add more stuff here later)

In terms of our experience using the Cleipnir reactive layer it is exceptionally easy to use once the basics is learned. Although Cleipnir currently lacks support for the majority of the reactive operators listed in the documentation. The current support does however cover most used reactive operators. During development only a single instance did we encounter an issue in which we required the use of a reactive operator that the reactive layer did not support. Thankfully Thomas added that missing reactive operators within a few hours, essentially proving that Cleipnir's current design allows for developers to easily add missing reactive operators should the need ever arise. As for the usage of the reactive paradigm in the protocol workflow. The code operations performed over the reactive streams works well and are easy to keep track of due to how simple it is to chain reactive operators. On the other hand, chaining reactive operations can be somewhat restricting in some circumstances. The most troublesome issue encountered in regards to working with reactive operators was to handle exceptions to the protocol workflow. In our case stopping the reactive operators when a view-change occurred was quite troublesome to implement. When the program is required to wait for a reactive \code{Source} to finish its operations, the \code{Source} must receive an item in a stream which manages to pass an perform each and every reactive operator that is chained to the \code{Source} object. This functionality can get very easily stuck when the source doesn't get the desired items to the stream. There are two notable workarounds to this problem. The first is to simply ignore the problem since its \code{Source} objects should only be listened to in \code{CTask} asynchronous functions, therefore it won't block the main execution thread even if it never finishes all of the reactive operators. Meaning the program simply creates new iterations for the workflow whenever the protocol starts and never stops any existing asynchronous operations that are stuck. This can be achieved if the reactive stream has strict \code{Where} clauses as it allows for the old listeners to not be affected by any new items received in the reactive stream. The \code{Where} clause filters out the items long before it can affect the program in any way. This means the workaround is essentially just letting the listener run stuck until it is eventually garbage collected. This method does slow the system down somewhat since the old \code{Source} objects are still actively listening, receiving and filtering out items emitted to the stream even if it can never proceed past the \code{Where} clause. The second workaround uses the \code{Merge} operator to have the listener listen to changes on two different streams. By this method it is possible to effectively terminate the listener if it receives an item from the second source, as this is counted as irregular activity. This is the method used in our \ac{pbft} implementation to handle exiting active instances of the \ac{pbft} workflow in order to change view for the system. This workaround also has its fair share of issues. In order to use the \code{Merge} operator it requires both the \code{Source} objects to listen for the same type of object. This is not always easy to coordinate, especially when the other operators for the listener transform the stream to work on another object type. In addition, the \code{Merge} operator also works like any other operator. If the \code{Merge} is triggered by the other source object and the operator is called early in the stream, then the item received is still required to pass the other operators in order to terminate the listener. Which puts it back to the state of the original problem. The item received by the other source must also be unique so that the rest of the workflow can terminate the process when it receives the item from that other \code{Source} object.

To summarize, the use of reactive handlers works well for segmenting operations to perform for the consensus algorithm when a new event is received in the network layer. In addition it is relatively easy for developers to use and is a lot easier to read the workflow in comparison to traditional programming. However, reactive handlers can be tricky to deal with when used in protocol workflow that needs to handle exceptions to the normal workflow. As consensus algorithms must handle situations where parties on the network stop responding, this can become a rather frequent issue. It therefore would be most beneficial if additional workarounds were discovered for handling this issue.  

\subsection{Cleipnir}
%-Overall knowledge for Cleipnir
%-Issues and advantages in regards to the topics listed over. For instance a lot of time was wasted due to not fully grasping how Cleipnir work
%internally when performing the reactive part and the CAwaitable emission --> resulting a month of frustration trying to figure out why collision errors occur.
%-Lack of documentation can be quite fatal for continued support.
%-Cleipnir and how it interacts with the other programming paradigms. Eks: A clear distinction has to made in regards to what code is run inside Cleipnir(the persistent part) and what is not(ephemeral)

As for our experience with using Cleipnir during this thesis it has been a mixed experience. The most challenging part of Cleipnir was learning about its functionality when we only had access to its source code and a few practical examples. Bakkevig previously also seemed to struggle in this department in his thesis~\cite[p.~43-44]{PAPER:EivindPaper}. This is somewhat our fault as we were not accustomed to learning about frameworks by reading its source code. During our study practically all tools and frameworks used had a form of written documentation. Although not all frameworks have well written documentations, frameworks usually have some form of community that uses which you can discuss unexpected issues when the need arises. As Cleipnir is still in development it obviously does not have a community. We also understand that since Cleinir is constantly being updated, writing a detailed documentation could be seen as wasteful. This is because the functionality changes frequently which means that the documentation would also need to be constantly updated, leading to a lot of extra work for each update. However, we do share Bakkevig's opinion that if  Cleipnir is to become well liked by developers, time must be invested into writing at least a small description for its unique components as well as a guideline for how each tool available in the framework should be used and what users should actively avoid. 

Cleipnir does have a lot of different practical examples that are very efficient in teaching users the basics of Cleipnir. It is possible to learn a lot through the practical examples, however without a written documentation it is very likely that the user needs to make assumptions on the tools used. In the case where the assumption is wrong it leads to the user experiencing both confusion and frustration when things are not working as intended. We were lucky enough that Stidsborg was available to answer any questions we had in regards to Cleipnir, but we still made some misconceptions which lead to problems for the design of our application. The biggest misconception being the usage of \code{CTask} which lead to our project being delayed for about a month due to confusion as to where the additional threads came that lead to many race conditions.   In short we learned that making assumptions can be quite detrimental and we should have perhaps queried Stidsborg earlier in the development about the difference between Cleipnir implementation of commonly used classes compared to their traditional use. 