\chapter{Conclusion}
\label{chapter:Con}
\iffalse
This chapter concludes the thesis by first listing the lessons we learned while working on this thesis. Then we list the potential future work which can be applied to the \ac{pbft} implementation.
Finally a conclusion is drawn for the work performed for this thesis.

\input{sections/learned}

\section{Future Work}
%1 mention fixing the broken public key system, and give examples(if you can think of any).
%2 potential things: 1. fix it so that the protocol workflow can handle any message being received in any order or 2. Implement a timeout process for the commit section so that the process can not become stuck in any scenario. Both are somewhat needed, but I have no idea how I can handle waiting for prepares messages before receiving the pre-prepare.
%3 Fix persistency. We believe we layed most of the foundation in regards to getting the system to be persistent. However, as mention in imp 2 issues are mainly present. 1. figure out a way to get rid of the original source referanse/access the original source reference so there is no longer duplicate requests. 2. Something is wrong with the synchronization. Not sure what is the cause, assume its the synchronization process is not fully finished before a new request is added.
% 4 Generally make the application and client more interesting. Currently the application state is a simple list of commands written to the console. Make the application actually perform a set of commands, and redesign the client to accomodate for this change.

As mentioned in \autoref{chapter:Design} our current cryptographic signature architecture is susceptible to impersonation and sybil attacks. Clearly keeping public keys ephemeral and generating them uniquely before start up is not a smart design when the system supports persistency. Creating static private and public keys is also not recommended as this would make the system less secure. The simplest solution would be to generate a couple unique key pairs for each replica and have these stored securely or given to the system by a separate trusted system. This system could for instance be a database where the cryptographic keys are stored encrypted. During system startup or during certain scenarios, such as view-changes and or system restarts, the replica reassigns its current cryptographic key pairs and re-establishes its secret key with the other replicas in the system. The other replicas only accept the renewed connection if the separate system acknowledges that the public key given matches one of the unique public keys that replica can have.

Currently we are using a digital signatures scheme for all message types, with the exception of the session messages, which is unnecessary and only slows down the system. The desired alternative is to follow the original \ac{pbft} system model and use \ac{mac} for authentication instead, as this would be more efficient. Although, we still recommend to continue to use the digital signature structure for view-change and new-view messages. Otherwise the view-change workflow would need to be redesigned to follow the more advanced workflow described in Castro's and Liskov's updated paper for \ac{pbft}~\cite[p.~410-414]{PAPER:PBFTRecovery}.

The protocol workflow currently suffers from the inability to handle pre-prepare and prepare being received out of order. In addition, prepare messages can also be lost if the message is received before the prepare listener is initialized. As described in \autoref{sec:protocolwork} this issue can cause the workflow to become stuck if too many prepare messages are lost while the workflow waits for a pre-prepare message. This is obviously something that should be corrected if the application is to be used in the future. One workaround to this problem would be to have a timeout functionality active during the period where the workflow waits for the desired number of prepare and commit messages. The timeout is stopped if both the reactive listeners have successfully created both protocol certificates. Otherwise the timeout expires and the reactive listeners are terminated using the same functionality used for the pre-prepare listener. In order for this functionality to be possible, another \code{Source} object would need to be added as the reactive stream used for reactive listeners for the prepare and commit message is of type \code{Stream<CList<PhaseMessage>~>} due to the stream being transformed by the \code{Scan} operator.

Solving the actual message order issue is a lot more difficult. It is not as simple as to initialize the prepare listener earlier as the listener needs to filter away any phase message that has a different sequence number than its current iteration. Unfortunately, non-primary sets the current sequence number based on the received pre-prepare, creating quite the conundrum. One solution to this problem would be for the server to store copies of the phase messages received in the network layer. By having this logger store the list of phase messages within a dictionary, it would be possible for the workflow to easily search for missing phase messages. Obviously the phase message records would be garbage collected once the protocol has successfully created the two desired protocol certificates for a given sequence number. This would however cause additional complexity to the protocol workflow as functionality for looking up and re-emitting lost phase messages would need to be added.

Currently our application does not fully support persistency. In the future it would be beneficial for both Cleipnir and our application if the issues described in \autoref{chapter:Imp} can be fixed to allow for our application to fully test Cleipnir's capability in regards to persistency. All of the groundwork has been laid for the application to work with persistency. This includes assigning all protocol object types their proper serialization and deserialization for Cleipnir to use, which have been tested on a smaller scale and works as intended. In addition, the network functionality for replicas to reconnect to the system has already been implemented and tested. The only thing left is for the system to successfully read the data stored by Cleipnirs storage engine and successfully restore its old state.
There are at least two notable issues that must be fixed in order for the application to become persistent. The first issue is that the original \code{Source} objects are duplicated by having Cleipnir somehow restore the original \code{Source} while also creating the desired new copy which was supposed to replace the old. Currently both \code{Source} objects react whenever new items are emitted to them by the network layer, meaning that for the protocol workflow, two iterations are created for a single sequence number. This in turn creates issues for the logger when multiple records for the same sequence number is stored. The second issue is that the logger synchronization isn't working properly and as a result records in the logger disappear after the replica restarts. This issue is most likely due to the synchronization either not being fully finished before moving with other operations or the synchronization is not done properly and as a result, some records are skipped. We assume this issue is caused by incorrect usage of \code{Sync} points set for Cleipnir, resulting in the state not being persisted correctly. As for the duplicate \code{Source} objects we are frankly not quite sure how this issue occurs. We theorize that it may occur due to some records being persisted in multiple objects, which in turn when persisted are not treated as the same \code{Source} object, leading to the duplicate issue. If this is the case, the issue would lie in the relationship between the server and the protocol workflow.

Generally the application functionality could be a lot more advanced than it is now. Currently the only operation the application performs after a request is processed successfully though the \ac{pbft} algorithm is simply printing the message attached to the request to the console window. The message is then added to a \code{CList} representing the state of the system. In the future it would be beneficial if the application functionality was changed to be a bit more practical. For instance, changing the message content in the request to instead be an operation which is performed by the application. The state list would then instead store a record of the operation performed as well as whether or not the application was able to perform the requested operation. In order to change the application functionality, the client functionality for creating requests must also be adjusted.

\section{Conclusion}
\iffalse
%clearly state that you accomplish the goal of the thesis.
%Clearly state the answer to the main research question
%Summarize and reflect on the research done for the thesis. In our case discoveries you've made based on usage of Cleipnir + async
%future work + what you have learned --> seperate segments
In conclusion we achieved our goal of creating a \ac{pbft} implementation using Cleipnir with the intended focus of making it faithful to the protocol description which also takes advantage asynchronous and reactive programming paradigms.
Original goal: Our goal for this thesis is to use the Cleipnir framework to implement the Practical Byzantine Fault Tolerance (PBFT) consensus algorithm using functionality from both asynchronous programming and reactive programming. The desired PBFT implementation
\fi
In conclusion, we achieved our goal of creating a simplistic \ac{pbft} implementation using Cleipnir with the intended focus of making it faithful to the protocol description, which also is designed to take advantage of asynchronous and reactive programming paradigms. The result is \ac{pbft} implementation that can perform the \ac{pbft} protocol over several multiple clients and has functional checkpoint and view-change functionality. We managed to design a normal workflow that fit our original criteria, but unfortunately, the protocol struggles with handling out-of-order protocol messages. The checkpoint and view-change workflow became too complex for the processes to be handled within a single function. Persistency functionality was sadly not successful for our \ac{pbft} implementation. Asynchronous programming is shown to be helpful when designing consensus algorithms. Asynchronous programming was notably useful in regards to networking functionality and for designing multi-client protocol workflows.
Similarly, reactive programming turns out to be fairly helpful for handling the operations regarding protocol messages and other event-based processes. Reactive programming, however, did appear to struggle with protocol message ordering when using a synchronous design. These two programming paradigms showed quite clearly that they work well together. We believe implementation consensus algorithms can be further simplified using these tools in the future, despite the problems addressed in this thesis. In regards to the Cleipnir framework, we acknowledge that the overall workflow of the Cleipnir reactive framework is user-friendly and has, for the most part, the functionality desired for designing a proper event handler for a consensus algorithm. We were unsuccessful in evaluating Cleipnir’s persistency functionality on our application. However, based on our experience with using the hybrid persistency functionality on our implementation. In addition to testing the persistency functionality for smaller parts of the program, we deem Cleipnir`s persistency functionality to be excellent.
To conclude this thesis, we do believe that the tools we have tested and evaluated during our \ac{pbft} implementation do make it easier to design consensus algorithms. In the future, we believe that consensus algorithms can be implemented simpler and more accurately to the protocol description. However, we acknowledge that due to the complex nature of distributed systems, it will be challenging to create accurate consensus algorithm implementations due to the numerous problems that can occur.
\fi

This chapter concludes the thesis by first listing the lessons we learned while working on the thesis. Then we list the potential future work which can be applied to the \ac{pbft} implementation.
Finally, a conclusion is drawn for the work performed for this thesis.

\input{sections/learned}

\section{Future Work}
As mentioned in \autoref{chapter:Design} our current cryptographic signature architecture is susceptible to impersonation and spoofing attacks. Clearly, keeping public keys ephemeral and generating them uniquely before start-up was not a smart design when the system supports persistency. Creating static private and public keys is also not recommended since this design would make the system less secure. One solution would be to generate a couple of unique key pairs for each replica and have these stored securely or given to the system by a separate trusted system. This system could, for instance, be a database where the cryptographic keys are stored encrypted. During system start-up or during certain scenarios, such as view-changes and or system restarts, the replica reassigns its current cryptographic key pairs and re-establishes its secret key with the other replicas in the system. The other replicas only accept the renewed connection if the separate system acknowledges that the public key given matches one of the unique public keys listed for that replica.

We are currently using a digital signatures scheme for all message types, except for the session messages. This is frankly unnecessary and only slows down the system. The desired alternative is to follow the original \ac{pbft} system model and use \ac{mac} for authentication instead, as this would be more efficient. Although, we still recommend continuing to use the digital signature structure for view-change and new-view messages. Otherwise, the view-change workflow would need to be redesigned to follow the more advanced workflow described in Castro’s and Liskov’s updated paper for \ac{pbft}~\cite[p.~410-414]{PAPER:PBFTRecovery}.

The protocol workflow currently suffers from the inability to handle pre-prepare and prepare being received out of order. In addition, prepare messages can also be lost if the message is received before the prepare listener is initialized. As described in \autoref{sec:protocolwork} this issue can cause the workflow to become stuck if too many prepare messages are lost while the workflow waits for a pre-prepare message. This is something that should be corrected if the application is to be used in the future. A workaround to this problem would be to have a timeout functionality active when the workflow waits for the desired number of prepare and commit messages. The timeout is stopped if both the reactive listeners have successfully created both protocol certificates. Otherwise, the timeout expires, and the reactive listeners are terminated using the same functionality used for the pre-prepare listener. For this functionality to be possible, another \code{Source} object would need to be added to the workflow to work with the \code{Merge} operator. This is because the reactive stream for reactive listeners to the prepare and commit message is of type \code{Stream<CList<PhaseMessage>~>} due to the stream being transformed by the \code{Scan} operator.

Solving the actual message ordering issue is a lot more complicated. It is not as simple as initializing the prepare listener earlier, as the listener needs to filter away any phase message with a different sequence number than its current iteration. Unfortunately, non-primary replicas set the current sequence number based on the received pre-prepare message, creating quite the conundrum. A solution to this problem is making the server store copies of the phase messages received in the network layer. By having this logger store a list of phase messages received for a sequence number within a dictionary, it would be possible for the workflow to easily search for missing phase messages. The phase message records stored in this logger would have to be garbage collected once the protocol has successfully created the two desired protocol certificates for the given sequence number. However, this would cause additional complexity to the protocol workflow as functionality for looking up, and re-emitting lost phase messages would need to be added.

Currently, our application does not fully support persistency. In the future, it would be favorable for both Cleipnir and our application if the issues described in \autoref{chapter:Imp} can be fixed to allow for our application to thoroughly test Cleipnir’s capability in regards to persistency. The groundwork has been laid for the application to work with persistency. This includes assigning all protocol object types their proper serialization and deserialization functions for Cleipnir to use, which have been tested on a smaller scale and works as intended. In addition, the network functionality for replicas to reconnect to the system has already been implemented and tested. The only thing left is for the system to successfully read the data stored by Cleipnirs storage engine and successfully restore its old state.
There are at least two notable issues that must be fixed for the application to become persistent. The first issue is that the original \code{Source} objects are duplicated by having Cleipnir somehow restore the original \code{Source} while also creating the desired new copy, which was supposed to replace the old. Currently, both \code{Source} objects react whenever new items are emitted to them by the network layer, meaning that for the protocol workflow, two iterations are created for a single sequence number. This, in turn, creates issues for the logger when multiple records for the same sequence number are stored. The second issue is that the logger synchronization isn’t working properly and as a result, records in the logger disappear after the replica restarts. This issue likely due to the synchronization not being fully finished before moving with other operations, or the synchronization is not done correctly, and as a result, some records are skipped. We assume this issue is caused by incorrect usage of \code{Sync} points set for Cleipnir, resulting in the state not being persisted correctly. As for the duplicate \code{Source} objects, we are frankly not quite sure how this issue occurs. We theorize that it may occur due to some records being persisted in multiple objects, and because of this, when the objects are persisted, the objects are not treated as the same \code{Source} object, leading to the duplicate \code{Source} object. If this is the case, the issue lies in the relationship between the server and the protocol workflow.

Generally, the application functionality could be a lot more advanced than it is now. Currently, the only operation the application performs after a request is processed successfully through the \ac{pbft} algorithm is simply printing the message attached to the request to the console window. The message is then added to a \code{CList} representing the state of the system. In the future, it would be beneficial if the application functionality was changed to be a bit more practical. For instance, changing the message content in the request to be an operation that is to be performed by the application instead of a string. The state list would then rather store a record of the operation performed and whether or not the application successfully performed the requested operation. In order to change the application functionality, the client functionality for creating requests must also be adjusted.

\section{Conclusion}
In conclusion, we achieved our goal of creating a simplistic \ac{pbft} implementation using Cleipnir with the intended focus of making it faithful to the protocol description, which also is designed to take advantage of asynchronous and reactive programming paradigms. The result is \ac{pbft} implementation that can perform the \ac{pbft} protocol over several multiple clients and has functional checkpoint and view-change functionality. We managed to design a normal workflow that fit our original criteria, but unfortunately, the protocol struggles with handling out-of-order protocol messages. The checkpoint and view-change workflow became too complex for the processes to be handled within a single function. Persistency functionality was sadly not successful for our \ac{pbft} implementation. Asynchronous programming is shown to be helpful when designing consensus algorithms. Asynchronous programming was notably useful in regards to networking functionality and for designing multi-client protocol workflows.
Similarly, reactive programming turns out to be fairly helpful for handling the operations regarding protocol messages and other event-based processes. Reactive programming, however, did appear to struggle with protocol message ordering when using synchronous design. These two programming paradigms showed quite clearly that they work well together. We believe implementation consensus algorithms can be further simplified using these tools in the future, despite the problems addressed in this thesis. In regards to the Cleipnir framework, we acknowledge that the overall workflow of the Cleipnir reactive framework is user-friendly and has, for the most part, the functionality desired for designing a proper event handler for a consensus algorithm. We were unsuccessful in evaluating Cleipnir’s persistency functionality on our application. However, based on our experience with using the hybrid persistency functionality on our implementation. In addition to testing the persistency functionality for smaller parts of the program, we deem Cleipnir’s persistency functionality to be excellent.
To conclude this thesis, we do believe that the tools we have tested and evaluated during our \ac{pbft} implementation do make it easier to design consensus algorithms. In the future, we believe that consensus algorithms can be implemented simpler and more accurately to the protocol description. However, we acknowledge that due to the complex nature of distributed systems, it will be challenging to create accurate consensus algorithm implementations due to the numerous problems that can occur.

